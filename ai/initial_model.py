import cv2
import mediapipe as mp
import numpy as np
import time
import math

# ==============================
# ì¹´ë©”ë¼ ë²ˆí˜¸ ì„¤ì •_ ê¸°ë³¸ íƒ‘ì¬ëœ ì¹´ë©”ë¼ëŠ” 0ë²ˆ
# ==============================
cap = cv2.VideoCapture(0)

# ==============================
# MediaPipe
# ==============================
mp_pose = mp.solutions.pose
mp_face = mp.solutions.face_mesh
mp_draw = mp.solutions.drawing_utils

pose = mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

face_mesh = mp_face.FaceMesh(
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# ==============================
# Calibration & Focus Params
# í™”ë©´ ìœ„ì¹˜ ì¡°ì •ì„ ìœ„í•œ ì´ˆê¸° ìº˜ë¦¬ë¸Œë ˆì´ì…˜
# ==============================
CALIB_TIME = 3.0
baseline_data = []
baseline_done = False
start_time = time.time()

# Threshold ê°’ - ì‹œì„ ë§Œ ì²´í¬
HEAD_YAW_TH = 15      # ì¢Œìš° íšŒì „ threshold
HEAD_PITCH_TH = 15    # ìœ„ì•„ë˜ íšŒì „ threshold
GAZE_RATIO_TH = 0.10  # ì‹œì„  ë¹„ìœ¨ threshold
EYE_AR_THRESHOLD = 0.15  # ëˆˆ ê¹œë¹¡ì„ threshold

FOCUS_TIME = 3  # ì„ì˜ ì„¤ì •
focus_start = None
reward = 0

# ==============================
# Helper Functions
# ==============================
def calc_head_pose(face_landmarks, w, h):
    """head pose ê³„ì‚°"""
    nose_tip = face_landmarks.landmark[1]
    chin = face_landmarks.landmark[152]
    left_eye_outer = face_landmarks.landmark[33]
    right_eye_outer = face_landmarks.landmark[263]
    left_mouth = face_landmarks.landmark[61]
    right_mouth = face_landmarks.landmark[291]
    
    nose_2d = np.array([nose_tip.x * w, nose_tip.y * h])
    chin_2d = np.array([chin.x * w, chin.y * h])
    left_eye_2d = np.array([left_eye_outer.x * w, left_eye_outer.y * h])
    right_eye_2d = np.array([right_eye_outer.x * w, right_eye_outer.y * h])
    left_mouth_2d = np.array([left_mouth.x * w, left_mouth.y * h])
    right_mouth_2d = np.array([right_mouth.x * w, right_mouth.y * h])
    
    eye_center = (left_eye_2d + right_eye_2d) / 2
    eye_width = np.linalg.norm(right_eye_2d - left_eye_2d)
    nose_offset = nose_2d[0] - eye_center[0]
    yaw = (nose_offset / eye_width) * 50
    
    face_height = np.linalg.norm(chin_2d - nose_2d)
    mouth_center = (left_mouth_2d + right_mouth_2d) / 2
    vertical_offset = mouth_center[1] - eye_center[1]
    pitch = (vertical_offset / face_height) * 50
    
    return yaw, pitch


def calc_eye_aspect_ratio(face_landmarks, eye_points):
    """
    Eye Aspect Ratio (EAR) ê³„ì‚° - ëˆˆì´ ì–¼ë§ˆë‚˜ ì—´ë ¤ìˆëŠ”ì§€
    eye_points: [top, bottom, left, right, top2, bottom2] ì¸ë±ìŠ¤
    """
    # ìˆ˜ì§ ê±°ë¦¬ 2ê°œ
    vertical1 = abs(face_landmarks.landmark[eye_points[0]].y - 
                    face_landmarks.landmark[eye_points[1]].y)
    vertical2 = abs(face_landmarks.landmark[eye_points[4]].y - 
                    face_landmarks.landmark[eye_points[5]].y)
    
    # ìˆ˜í‰ ê±°ë¦¬
    horizontal = abs(face_landmarks.landmark[eye_points[2]].x - 
                     face_landmarks.landmark[eye_points[3]].x)
    
    # EAR ê³„ì‚°
    ear = (vertical1 + vertical2) / (2.0 * horizontal)
    return ear


def is_eye_open(face_landmarks):
    """ì–‘ìª½ ëˆˆì´ ë– ì ¸ ìˆëŠ”ì§€ í™•ì¸"""
    # ì™¼ìª½ ëˆˆ ëœë“œë§ˆí¬: ìœ„, ì•„ë˜, ì¢Œ, ìš°, ìœ„2, ì•„ë˜2
    left_eye_points = [159, 145, 33, 133, 158, 153]
    # ì˜¤ë¥¸ìª½ ëˆˆ ëœë“œë§ˆí¬: ìœ„, ì•„ë˜, ì¢Œ, ìš°, ìœ„2, ì•„ë˜2  
    right_eye_points = [386, 374, 362, 263, 385, 380]
    
    left_ear = calc_eye_aspect_ratio(face_landmarks, left_eye_points)
    right_ear = calc_eye_aspect_ratio(face_landmarks, right_eye_points)
    
    avg_ear = (left_ear + right_ear) / 2.0
    
    return avg_ear > EYE_AR_THRESHOLD, avg_ear


def calc_gaze_ratio(face_landmarks):
    """
    ëˆˆ ì•ˆì—ì„œ irisì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ë¹„ìœ¨ë¡œ ê³„ì‚°
    ì™¼ìª½ ëˆˆê³¼ ì˜¤ë¥¸ìª½ ëˆˆ ê°ê° ê³„ì‚°
    """
    # ì™¼ìª½ ëˆˆ ëœë“œë§ˆí¬
    left_eye_left = face_landmarks.landmark[33]
    left_eye_right = face_landmarks.landmark[133]
    left_eye_top = face_landmarks.landmark[159]
    left_eye_bottom = face_landmarks.landmark[145]
    left_iris_center = face_landmarks.landmark[468]
    
    # ì˜¤ë¥¸ìª½ ëˆˆ ëœë“œë§ˆí¬
    right_eye_left = face_landmarks.landmark[362]
    right_eye_right = face_landmarks.landmark[263]
    right_eye_top = face_landmarks.landmark[386]
    right_eye_bottom = face_landmarks.landmark[374]
    right_iris_center = face_landmarks.landmark[473]
    
    # ì™¼ìª½ ëˆˆ - ì¢Œìš° ë¹„ìœ¨
    left_eye_width = abs(left_eye_right.x - left_eye_left.x)
    left_iris_x_from_left = abs(left_iris_center.x - left_eye_left.x)
    left_ratio_x = left_iris_x_from_left / left_eye_width if left_eye_width > 0 else 0.5
    
    # ì™¼ìª½ ëˆˆ - ìƒí•˜ ë¹„ìœ¨
    left_eye_height = abs(left_eye_bottom.y - left_eye_top.y)
    left_iris_y_from_top = abs(left_iris_center.y - left_eye_top.y)
    left_ratio_y = left_iris_y_from_top / left_eye_height if left_eye_height > 0 else 0.5
    
    # ì˜¤ë¥¸ìª½ ëˆˆ - ì¢Œìš° ë¹„ìœ¨
    right_eye_width = abs(right_eye_right.x - right_eye_left.x)
    right_iris_x_from_left = abs(right_iris_center.x - right_eye_left.x)
    right_ratio_x = right_iris_x_from_left / right_eye_width if right_eye_width > 0 else 0.5
    
    # ì˜¤ë¥¸ìª½ ëˆˆ - ìƒí•˜ ë¹„ìœ¨
    right_eye_height = abs(right_eye_bottom.y - right_eye_top.y)
    right_iris_y_from_top = abs(right_iris_center.y - right_eye_top.y)
    right_ratio_y = right_iris_y_from_top / right_eye_height if right_eye_height > 0 else 0.5
    
    # ì–‘ìª½ ëˆˆ í‰ê· 
    avg_ratio_x = (left_ratio_x + right_ratio_x) / 2
    avg_ratio_y = (left_ratio_y + right_ratio_y) / 2
    
    return avg_ratio_x, avg_ratio_y


# ==============================
# ë©”ì¸ ì‘ë™
# ==============================
while cap.isOpened():
    success, image = cap.read()
    image = cv2.flip(image, 1)
    if not success:
        print("ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    h, w, _ = image.shape
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    pose_result = pose.process(rgb)
    face_result = face_mesh.process(rgb)

    # --------------------------
    # Draw Pose
    # --------------------------
    if pose_result.pose_landmarks:
        mp_draw.draw_landmarks(
            image,
            pose_result.pose_landmarks,
            mp_pose.POSE_CONNECTIONS
        )

    # --------------------------
    # Face / Gaze / Head Pose
    # --------------------------
    if face_result.multi_face_landmarks:
        face = face_result.multi_face_landmarks[0]

        yaw, pitch = calc_head_pose(face, w, h)
        gaze_x, gaze_y = calc_gaze_ratio(face)
        eyes_open, ear_value = is_eye_open(face)

        current_time = time.time()

        # ---------- Calibration ----------
        if not baseline_done:
            if current_time - start_time < CALIB_TIME:
                baseline_data.append([yaw, pitch, gaze_x, gaze_y])
                cv2.putText(
                    image,
                    "Calibrating... Look at the book",
                    (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.9,
                    (0, 255, 255),
                    2
                )
            else:
                baseline = np.mean(baseline_data, axis=0)
                base_yaw, base_pitch, base_gx, base_gy = baseline
                baseline_done = True
                print(f"Baseline set: Yaw={base_yaw:.2f}, Pitch={base_pitch:.2f}, GazeX={base_gx:.4f}, GazeY={base_gy:.4f}")
        else:
            # ---------- ëˆˆ ê¹œë¹¡ì„ ì²´í¬ ----------
            if not eyes_open:
                # ëˆˆ ê°ì•˜ì„ ë•ŒëŠ” ì´ì „ ìƒíƒœ ìœ ì§€ (íƒ€ì´ë¨¸ ë©ˆì¶”ì§€ ì•ŠìŒ)
                cv2.putText(image, "BLINKING (ignored)", (20, 40),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 165, 0), 2)
                cv2.putText(image, f"Reward: {reward}", (20, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)
                
                # Focus ì§„í–‰ ìƒí™©ì€ ê³„ì† í‘œì‹œ
                if focus_start is not None:
                    elapsed = current_time - focus_start
                    
                    # ëˆˆ ê°ì•˜ì–´ë„ ì‹œê°„ì€ ê³„ì† íë¦„
                    if elapsed >= FOCUS_TIME:
                        reward += 1
                        focus_start = current_time
                        print(f'ğŸ‰ Reward earned! Total: {reward}')
                    
                    progress = min(elapsed / FOCUS_TIME, 1.0)
                    bar_width = int(400 * progress)
                    cv2.rectangle(image, (20, 110), (420, 130), (50, 50, 50), -1)
                    cv2.rectangle(image, (20, 110), (20 + bar_width, 130), (255, 165, 0), -1)
                    cv2.putText(image, f"{elapsed:.1f}s / {FOCUS_TIME}s", (430, 125),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ëˆˆ ìƒíƒœ í‘œì‹œ
                cv2.putText(image, f"Eyes: CLOSED (EAR:{ear_value:.3f})", 
                           (20, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)
            else:
                # ---------- Focus íŒë‹¨ (ëˆˆ ë– ìˆì„ ë•Œë§Œ) ----------
                yaw_diff = abs(yaw - base_yaw)
                pitch_diff = abs(pitch - base_pitch)
                gaze_x_diff = abs(gaze_x - base_gx)
                gaze_y_diff = abs(gaze_y - base_gy)
                
                head_ok = (yaw_diff < HEAD_YAW_TH and pitch_diff < HEAD_PITCH_TH)
                gaze_ok = (gaze_x_diff < GAZE_RATIO_TH and gaze_y_diff < GAZE_RATIO_TH)

                # ì‹œì„ ë§Œìœ¼ë¡œ ì§‘ì¤‘ íŒë‹¨ (ê³ ê°œ ê°ë„ëŠ” ë¬´ê´€)
                focused = gaze_ok
                
                # ì§‘ì¤‘ ìœ í˜• íŒë³„ (í™”ë©´ í‘œì‹œìš©)
                if head_ok and gaze_ok:
                    focus_type = "FULL"  # ë¨¸ë¦¬ë„ ì •ë©´, ì‹œì„ ë„ ì •ë©´
                elif gaze_ok:
                    focus_type = "GAZE"  # ë¨¸ë¦¬ëŠ” ëŒë ¸ì§€ë§Œ ì‹œì„ ì€ í™”ë©´
                else:
                    focus_type = "NONE"  # ì‹œì„ ì´ ë²—ì–´ë‚¨
                
                # ë””ë²„ê·¸ ì¶œë ¥
                if not focused:
                    print(f'âŒ NOT FOCUSED - Gaze(X:{gaze_x_diff:.3f}/{GAZE_RATIO_TH} Y:{gaze_y_diff:.3f}/{GAZE_RATIO_TH}) | Head(Y:{yaw_diff:.1f} P:{pitch_diff:.1f})')
                
                if focused:
                    if focus_start is None:
                        focus_start = current_time
                        print(f'âœ“ Focus started ({focus_type})')
                    else:
                        elapsed = current_time - focus_start
                        
                        if elapsed >= FOCUS_TIME:
                            reward += 1
                            focus_start = current_time
                            print(f'ğŸ‰ Reward earned! Total: {reward}')
                else:
                    if focus_start is not None:
                        print('âœ— Focus lost - timer reset')
                    focus_start = None

                # ---------- UI ----------
                # ì§‘ì¤‘ ìƒíƒœì— ë”°ë¥¸ í‘œì‹œ
                if focus_type == "FULL":
                    status = "FOCUSED (Full)"
                    color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
                elif focus_type == "GAZE":
                    status = "FOCUSED (Gaze Only)"
                    color = (0, 200, 255)  # í•˜ëŠ˜ìƒ‰
                else:
                    status = "NOT FOCUSED"
                    color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰

                cv2.putText(image, status, (20, 40),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)
                cv2.putText(image, f"Reward: {reward}", (20, 80),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)
                
                # Focus ì§„í–‰ ìƒí™© í‘œì‹œ
                if focus_start is not None:
                    elapsed = current_time - focus_start
                    progress = min(elapsed / FOCUS_TIME, 1.0)
                    bar_width = int(400 * progress)
                    cv2.rectangle(image, (20, 110), (420, 130), (50, 50, 50), -1)
                    cv2.rectangle(image, (20, 110), (20 + bar_width, 130), color, -1)
                    cv2.putText(image, f"{elapsed:.1f}s / {FOCUS_TIME}s", (430, 125),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ìƒì„¸ ë””ë²„ê·¸ ì •ë³´
                head_color = (0, 255, 0) if head_ok else (100, 100, 100)  # íšŒìƒ‰ìœ¼ë¡œ (ì°¸ê³ ìš©)
                gaze_color = (0, 255, 0) if gaze_ok else (0, 0, 255)
                
                cv2.putText(image, f"Head: {'OK' if head_ok else 'NG'} (Y:{yaw_diff:.1f}/{HEAD_YAW_TH} P:{pitch_diff:.1f}/{HEAD_PITCH_TH}) [REF]", 
                           (20, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, head_color, 1)
                cv2.putText(image, f"Gaze: {'OK' if gaze_ok else 'NG'} (X:{gaze_x_diff:.3f}/{GAZE_RATIO_TH} Y:{gaze_y_diff:.3f}/{GAZE_RATIO_TH}) [MAIN]", 
                           (20, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.6, gaze_color, 2)
                
                # ì‹¤ì‹œê°„ ì‹œì„  ë¹„ìœ¨ í‘œì‹œ (0.5 -> ì¤‘ì•™)
                cv2.putText(image, f"Gaze Ratio: X={gaze_x:.3f} Y={gaze_y:.3f} (0.5=center)", 
                           (20, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # ëˆˆ ìƒíƒœ í‘œì‹œ
                cv2.putText(image, f"Eyes: OPEN (EAR:{ear_value:.3f})", 
                           (20, 250), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # ì§‘ì¤‘ íŒë‹¨ ê¸°ì¤€ í‘œì‹œ
                cv2.putText(image, "Focus Criteria: GAZE ONLY", 
                           (20, 280), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

    cv2.imshow("Focus Detection System", image)

    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()