import React, { useState, useEffect, useRef } from 'react';
import { StyleSheet, Text, View } from 'react-native';
import { Camera, useCameraDevice, useFrameProcessor } from 'react-native-vision-camera';
import { useTensorflowModel } from 'react-native-fast-tflite';
import { useResizePlugin } from 'vision-camera-resize-plugin';
import { useSharedValue } from 'react-native-worklets-core';
import { runOnJS } from 'react-native-reanimated';

// === [ì„¤ì •] ===
const YAW_THRESHOLD = 0.25; // ì‹œì„  ì´íƒˆ ê¸°ì¤€ (ë¹„ìœ¨)
const EAR_THRESHOLD = 0.08; // ì¡¸ìŒ ê¸°ì¤€ (EAR)
const MOVEMENT_THRESHOLD = 20; // ì‚°ë§Œí•¨ ê¸°ì¤€ ì ìˆ˜

// í”„ë ˆì„ ì¹´ìš´íŠ¸ ê¸°ì¤€ (ëŒ€ëµ 30FPS ê¸°ì¤€)
// TFLiteëŠ” ë¹ ë¥´ê¸° ë•Œë¬¸ì— ì¹´ìš´íŠ¸ë¥¼ ë„‰ë„‰í•˜ê²Œ ì¡ìŠµë‹ˆë‹¤.
const AWAY_FRAME_LIMIT = 100; // ì•½ 3~5ì´ˆê°„ ì–¼êµ´ ì—†ìœ¼ë©´ ì´íƒˆ

const IDX = {
  LEFT_EYE: [159, 145, 33, 133],
  RIGHT_EYE: [386, 374, 362, 263],
  FACE_EDGES: [234, 454],
  NOSE_TIP: 1
};

interface Props {
  ws: WebSocket | null;
  classId: number;
  studentId: number;
  studentName: string;
  mode: "DIGITAL" | "NORMAL";
}

export default function TfliteFaceCam({ ws, classId, studentId, studentName, mode }: Props) {
  const device = useCameraDevice('front');
  const [permission, setPermission] = useState(false);
  
  // ëª¨ë¸ ë¡œë“œ
  const model = useTensorflowModel(require('../../../assets/face_landmarker.tflite'));
  const { resize } = useResizePlugin();

  const [status, setStatus] = useState("FOCUS");
  const lastAlertTime = useRef(0);
  
  // Worklet(UIìŠ¤ë ˆë“œ ë°–)ì—ì„œ ì“¸ ê°’ë“¤ì€ useSharedValue ì‚¬ìš©
  const faceMissingCount = useSharedValue(0);
  const lastNoseX = useSharedValue(0);
  const lastNoseY = useSharedValue(0);
  const movementScore = useSharedValue(0);
  
  // ì—°ì‚° ë¶€í•˜ ì¡°ì ˆìš© (í”„ë ˆì„ ìŠ¤í‚µ)
  const frameCounter = useSharedValue(0);

  useEffect(() => {
    (async () => {
      const status = await Camera.requestCameraPermission();
      setPermission(status === 'granted');
    })();
  }, []);

  // ğŸ“¡ JS ìŠ¤ë ˆë“œ: ì„œë²„ ì „ì†¡
  const sendAlert = (type: string, msg: string) => {
    setStatus(type);
    const now = Date.now();
    // 3ì´ˆ ì¿¨íƒ€ì„
    if (type !== "FOCUS" && now - lastAlertTime.current > 3000) {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({
          type, 
          message: msg, 
          classid: classId, 
          studentId, 
          studentName, 
          alertTime: new Date().toISOString()
        }));
        lastAlertTime.current = now;
        console.log(`ğŸ“¡ TFLite Alert [${mode}]: ${type} - ${msg}`);
      }
    }
  };

  // ğŸ§® [Worklet] ê±°ë¦¬ ê³„ì‚°
  const getDistance = (p1: number[], p2: number[]) => {
    'worklet';
    return Math.sqrt(Math.pow(p1[0] - p2[0], 2) + Math.pow(p1[1] - p2[1], 2));
  };

  // ğŸ§® [Worklet] EAR ê³„ì‚°
  const calculateEAR = (landmarks: Float32Array, indices: number[]) => {
    'worklet';
    const getPoint = (idx: number) => [landmarks[idx * 3], landmarks[idx * 3 + 1]];
    return getDistance(getPoint(indices[0]), getPoint(indices[1])) / getDistance(getPoint(indices[2]), getPoint(indices[3]));
  };

  const frameProcessor = useFrameProcessor((frame) => {
    'worklet';
    if (model.state !== 'loaded') return;

    // ì„±ëŠ¥ ìµœì í™”: 3í”„ë ˆì„ì— 1ë²ˆë§Œ ë¶„ì„ (ì•½ 10~20 FPS íš¨ê³¼)
    frameCounter.value += 1;
    if (frameCounter.value % 3 !== 0) return;

    // 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    const resized = resize(frame, {
      scale: { width: 192, height: 192 },
      pixelFormat: 'rgb',
      dataType: 'float32',
    });

    // 2. ëª¨ë¸ ì‹¤í–‰
    const outputs = model.model.runSync([resized]);
    const landmarks = outputs[0] as Float32Array;

    // [CASE 1] ì–¼êµ´ ì—†ìŒ (ìë¦¬ ì´íƒˆ ì²´í¬)
    if (landmarks.length < 100) {
      faceMissingCount.value += 1;
      if (faceMissingCount.value > AWAY_FRAME_LIMIT) { // 5ì´ˆ ì´ìƒ
        runOnJS(sendAlert)("AWAY", "ìë¦¬ ì´íƒˆ ê°ì§€ (5ì´ˆ)");
      }
      return;
    }
    
    // ì–¼êµ´ ì°¾ìŒ -> ì´íƒˆ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    faceMissingCount.value = 0;


    // --- ê³µí†µ ë°ì´í„° ì¶”ì¶œ ---
    const noseX = landmarks[IDX.NOSE_TIP * 3];
    const noseY = landmarks[IDX.NOSE_TIP * 3 + 1];

    // ì›€ì§ì„(Movement) ê³„ì‚° (ê³µí†µ)
    const diff = Math.abs(noseX - lastNoseX.value) + Math.abs(noseY - lastNoseY.value);
    lastNoseX.value = noseX;
    lastNoseY.value = noseY;

    // ì›€ì§ì„ ì ìˆ˜ ëˆ„ì 
    // TFLite ì¢Œí‘œëŠ” 192 ê¸°ì¤€ì´ë¯€ë¡œ ì›€ì§ì„ ì„ê³„ê°’ì„ ì‘ê²Œ(2~3) ì¡ìŒ
    if (diff > 2) movementScore.value += 1;
    else movementScore.value = Math.max(0, movementScore.value - 0.5);
    
    const isMovingTooMuch = movementScore.value > MOVEMENT_THRESHOLD;


    // ---------------------------------------------
    // ğŸ§  3. ëª¨ë“œë³„ ë¡œì§ ë¶„ê¸°
    // ---------------------------------------------
    
    if (mode === "DIGITAL") {
      // === [ë””ì§€í„¸ ìˆ˜ì—…]: ì‹œì„  + ì¡¸ìŒ + ì›€ì§ì„ ===
      
      // (A) ì¡¸ìŒ (EAR)
      const leftEAR = calculateEAR(landmarks, IDX.LEFT_EYE);
      const rightEAR = calculateEAR(landmarks, IDX.RIGHT_EYE);
      const avgEAR = (leftEAR + rightEAR) / 2;
      const isSleeping = avgEAR < EAR_THRESHOLD;

      // (B) ì‹œì„  (Yaw Ratio)
      const leftEdgeX = landmarks[IDX.FACE_EDGES[0] * 3];
      const rightEdgeX = landmarks[IDX.FACE_EDGES[1] * 3];
      const faceWidth = Math.abs(rightEdgeX - leftEdgeX);
      const yawRatio = (noseX - leftEdgeX) / faceWidth;
      const isLookingAway = Math.abs(yawRatio - 0.5) > YAW_THRESHOLD;

      // (C) ì¢…í•© íŒì • (ìš°ì„ ìˆœìœ„: ì´íƒˆ > ì¡¸ìŒ > ì‚°ë§Œ)
      if (isLookingAway) {
        runOnJS(sendAlert)("UNFOCUS", "ì‹œì„  ì´íƒˆ");
      } else if (isSleeping) {
        runOnJS(sendAlert)("UNFOCUS", "ì¡¸ìŒ ê°ì§€");
      } else if (isMovingTooMuch) {
        runOnJS(sendAlert)("UNFOCUS", "ì£¼ì˜ ì‚°ë§Œ (ì›€ì§ì„)"); // âœ¨ ì¶”ê°€ë¨
      } else {
        runOnJS(setStatus)("FOCUS");
      }

    } else {
      // === [ì¼ë°˜ ìˆ˜ì—…]: ì›€ì§ì„(ì‚°ë§Œí•¨) ì§‘ì¤‘ ===
      
      if (isMovingTooMuch) {
         runOnJS(sendAlert)("UNFOCUS", "ì£¼ì˜ ì‚°ë§Œ (ê³¼ë„í•œ ì›€ì§ì„)");
      } else {
         runOnJS(setStatus)("FOCUS");
      }
    }
  }, [model, mode]);

  if (!device || !permission) return <Text style={{color:'white'}}>AI ì¹´ë©”ë¼ ë¡œë”©ì¤‘...</Text>;

  return (
    <View style={styles.container}>
      <Camera
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        frameProcessor={frameProcessor}
        pixelFormat="yuv"
      />
      <View style={styles.overlay}>
        <Text style={{color: status==='FOCUS'?'lime':'red', fontSize:16, fontWeight:'bold'}}>
          [{mode}] {status}
        </Text>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: 'black', borderRadius: 20, overflow: 'hidden' },
  overlay: { position: 'absolute', bottom: 20, alignSelf: 'center', backgroundColor: 'rgba(0,0,0,0.6)', padding: 10, borderRadius: 8 }
});