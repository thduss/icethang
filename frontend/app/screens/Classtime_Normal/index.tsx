import React, { useEffect, useState, useRef } from "react";
import { View, StyleSheet, AppState, Platform, NativeModules, ActivityIndicator, TouchableOpacity, Text } from "react-native";
// ğŸš€ [ë³€ê²½] Vision Camera & TFLite ë¼ì´ë¸ŒëŸ¬ë¦¬
import { Camera, useCameraDevice, useCameraPermission, useFrameProcessor } from 'react-native-vision-camera';
import { useTensorflowModel } from 'react-native-fast-tflite';
import { useResizePlugin } from 'vision-camera-resize-plugin';
import { useSharedValue } from 'react-native-worklets-core';
import { runOnJS } from 'react-native-reanimated';

// import PipHandler, { usePipModeListener } from 'react-native-pip-android';
import { useRouter } from "expo-router";

import TrafficLight from "../../components/TrafficLight";
import ClassResultModal from "../../components/ClassResultModal";

import { Client } from "@stomp/stompjs";
import SockJS from "sockjs-client";
import { SOCKET_CONFIG } from "../../api/socket";
import { useSelector } from "react-redux";
import { RootState } from "../../store/stores";

const { OverlayModule } = NativeModules;

// AI ìƒíƒœ íƒ€ì… ì •ì˜
type AIStatus = "FOCUS" | "UNFOCUS" | "AWAY" | "SLEEPING";

// ğŸ§  [ì„¤ì •] AI ì„ê³„ê°’ (ì¡°ì ˆ ê°€ëŠ¥)
const YAW_THRESHOLD = 0.25; // ê³ ê°œ ëŒë¦¼ ê¸°ì¤€ (0.5ê°€ ì •ë©´, ì°¨ì´ 0.25 ì´ìƒì´ë©´ ì´íƒˆ)
const EAR_THRESHOLD = 0.08; // ëˆˆ ë– ì§ ê¸°ì¤€ (ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ê°ì€ ê²ƒ)
const MOVEMENT_THRESHOLD = 20; // ì›€ì§ì„ ì‚°ë§Œ ê¸°ì¤€

// ğŸ“ [ì„¤ì •] Face Mesh ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
const IDX = {
  // ì™¼ìª½ ëˆˆ (ìœ„, ì•„ë˜, ì™¼ìª½, ì˜¤ë¥¸ìª½)
  LEFT_EYE: [159, 145, 33, 133], 
  // ì˜¤ë¥¸ìª½ ëˆˆ (ìœ„, ì•„ë˜, ì™¼ìª½, ì˜¤ë¥¸ìª½)
  RIGHT_EYE: [386, 374, 362, 263],
  // ì–¼êµ´ ìœ¤ê³½ (ì™¼ìª½ ê·€, ì˜¤ë¥¸ìª½ ê·€) -> ê³ ê°œ ê°ë„ ê³„ì‚°ìš©
  FACE_EDGES: [234, 454], 
  // ì½” ë
  NOSE_TIP: 1 
};

export default function DigitalClassScreen() {
  const router = useRouter();
  // const inPipMode = usePipModeListener();
  const appState = useRef(AppState.currentState);
  
  // Redux ì •ë³´
  const { studentData } = useSelector((state: RootState) => state.auth);
  const classId = studentData?.classId?.toString() || "1";

  // ğŸš€ [ë³€ê²½] Vision Camera ì„¤ì •
  const { hasPermission, requestPermission } = useCameraPermission();
  const device = useCameraDevice('front');
  const model = useTensorflowModel({ url: 'file:///android_asset/face_landmarker.tflite' });
  const { resize } = useResizePlugin();

  const [isResultVisible, setIsResultVisible] = useState(false);
  const [studentStatus, setStudentStatus] = useState<AIStatus>("FOCUS");
  const [isConnected, setIsConnected] = useState(false);

  // ğŸ¤– AI SharedValues (Workletìš©)
  const faceMissingCount = useSharedValue(0);
  const lastNoseX = useSharedValue(0);
  const lastNoseY = useSharedValue(0);
  const movementScore = useSharedValue(0);
  
  // JS ìŠ¤ë ˆë“œìš© Refs
  const stompClient = useRef<Client | null>(null);
  const lastAlertTime = useRef(0);
  const gazeFailCount = useRef(0); // ì‹œì„ /ì¡¸ìŒ ëˆ„ì  ì¹´ìš´íŠ¸ (JSì¸¡)

  // ê¶Œí•œ ìš”ì²­
  useEffect(() => {
    if (!hasPermission) requestPermission();
  }, [hasPermission]);

  // ============================================================
  // ğŸ¤– 1. ì˜¨ë””ë°”ì´ìŠ¤ AI ë¡œì§ (Vision Camera Frame Processor)
  // ============================================================
  
  // JS ìŠ¤ë ˆë“œë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì „ë‹¬
  const updateAiStatusJS = (newStatus: AIStatus) => {
    setStudentStatus(prev => {
      // ìƒíƒœ ë³€ê²½ ì‹œ ì„œë²„ ì „ì†¡ ë¡œì§ í˜¸ì¶œì„ ìœ„í•´ ìƒíƒœê°’ ë³€ê²½
      if (prev !== newStatus) return newStatus;
      return prev;
    });
  };

  // ğŸ§® ê±°ë¦¬ ê³„ì‚° í—¬í¼ (Worklet)
  const getDistance = (p1: number[], p2: number[]) => {
    'worklet';
    return Math.sqrt(Math.pow(p1[0] - p2[0], 2) + Math.pow(p1[1] - p2[1], 2));
  };

  // ğŸ§® EAR(ëˆˆ ë– ì§) ê³„ì‚° í—¬í¼ (Worklet)
  const calculateEAR = (landmarks: Float32Array, indices: number[]) => {
    'worklet';
    const getPoint = (idx: number) => [landmarks[idx * 3], landmarks[idx * 3 + 1]];
    const vDist = getDistance(getPoint(indices[0]), getPoint(indices[1])); // ìƒí•˜
    const hDist = getDistance(getPoint(indices[2]), getPoint(indices[3])); // ì¢Œìš°
    return vDist / hDist;
  };

  const frameProcessor = useFrameProcessor((frame) => {
    'worklet';
    if (model.state !== 'loaded') return;

    // 1. ì „ì²˜ë¦¬ (192x192 RGB)
    const resized = resize(frame, {
      scale: { width: 192, height: 192 },
      pixelFormat: 'rgb',
      dataType: 'float32',
    });

    // 2. ëª¨ë¸ ì‹¤í–‰
    const outputs = model.model.runSync([resized]);
    const landmarks = outputs[0] as Float32Array;

    // [CASE 1] ì–¼êµ´ ì—†ìŒ (AWAY)
    // ì½” ë ì¢Œí‘œê°€ ê±°ì˜ 0ì´ë©´ ì–¼êµ´ ì—†ìŒìœ¼ë¡œ ê°„ì£¼ (ëª¨ë¸ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    // ë˜ëŠ” landmarks ë°°ì—´ ê°’ì´ ëª¨ë‘ 0ì¸ì§€ ì²´í¬. ì—¬ê¸°ì„œëŠ” ì½” ì¢Œí‘œ ìœ íš¨ì„±ìœ¼ë¡œ ì²´í¬.
    const noseX = landmarks[IDX.NOSE_TIP * 3];
    const noseY = landmarks[IDX.NOSE_TIP * 3 + 1];

    if (Math.abs(noseX) < 0.01 && Math.abs(noseY) < 0.01) {
      faceMissingCount.value += 1;
      if (faceMissingCount.value > 150) { // ì•½ 5ì´ˆ (30FPS ê¸°ì¤€)
        runOnJS(updateAiStatusJS)("AWAY");
      }
      return;
    }
    faceMissingCount.value = 0;

    // [CASE 2] ì¡¸ìŒ ê°ì§€ (EAR)
    const leftEAR = calculateEAR(landmarks, IDX.LEFT_EYE);
    const rightEAR = calculateEAR(landmarks, IDX.RIGHT_EYE);
    const avgEAR = (leftEAR + rightEAR) / 2;
    const isSleeping = avgEAR < EAR_THRESHOLD;

    // [CASE 3] ì‹œì„  ì´íƒˆ (Yaw Ratio)
    // ì–¼êµ´ ì™¼ìª½ë~ì˜¤ë¥¸ìª½ë ì‚¬ì´ì—ì„œ ì½”ê°€ ì–´ë””ì— ìˆëŠ”ì§€ ë¹„ìœ¨ ê³„ì‚°
    const leftEdgeX = landmarks[IDX.FACE_EDGES[0] * 3];
    const rightEdgeX = landmarks[IDX.FACE_EDGES[1] * 3];
    const faceWidth = Math.abs(rightEdgeX - leftEdgeX);
    
    // ì½”ê°€ ì •ì¤‘ì•™(0.5)ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ê°€
    const yawRatio = (noseX - leftEdgeX) / faceWidth;
    const isLookingAway = Math.abs(yawRatio - 0.5) > YAW_THRESHOLD;

    // [CASE 4] ì›€ì§ì„ (ì‚°ë§Œí•¨)
    const diff = Math.abs(noseX - lastNoseX.value) + Math.abs(noseY - lastNoseY.value);
    lastNoseX.value = noseX;
    lastNoseY.value = noseY;

    if (diff > 2.0) movementScore.value += 1;
    else movementScore.value = Math.max(0, movementScore.value - 0.5);
    const isMovingTooMuch = movementScore.value > MOVEMENT_THRESHOLD;

    // [ì¢…í•© íŒì •] ìš°ì„ ìˆœìœ„: ì´íƒˆ > ì¡¸ìŒ > ì‹œì„  > ì‚°ë§Œ
    if (isLookingAway) {
      runOnJS(updateAiStatusJS)("UNFOCUS"); // ì‹œì„  ì´íƒˆ
    } else if (isSleeping) {
      runOnJS(updateAiStatusJS)("UNFOCUS"); // ì¡¸ìŒ (ìƒíƒœê°’ í†µì¼)
    } else if (isMovingTooMuch) {
      runOnJS(updateAiStatusJS)("UNFOCUS"); // ì›€ì§ì„
    } else {
      runOnJS(updateAiStatusJS)("FOCUS");
    }

  }, [model]);

  // ============================================================
  // ğŸ”Œ 2. ìƒíƒœ ì²˜ë¦¬ ë° ì†Œì¼“ ì „ì†¡ (JS ìŠ¤ë ˆë“œ)
  // ============================================================
  useEffect(() => {
    // ìƒíƒœ ë³€ê²½ ì‹œ ì„œë²„ ì „ì†¡ & ì˜¤ë²„ë ˆì´ ì•Œë¦¼
    const now = Date.now();
    
    // FOCUSê°€ ì•„ë‹ˆë©´ ì „ì†¡ (ì¿¨íƒ€ì„ 3ì´ˆ)
    if (studentStatus !== "FOCUS" && (now - lastAlertTime.current > 3000)) {
      sendAlertToServer(studentStatus);
      lastAlertTime.current = now;

      // ì•ˆë“œë¡œì´ë“œ PiP ì˜¤ë²„ë ˆì´ ì•Œë¦¼
      // if (inPipMode && Platform.OS === 'android') {
      //   OverlayModule?.showOverlay("ë°”ë¥¸ ìì„¸ë¡œ ì§‘ì¤‘í•´ì£¼ì„¸ìš”!", false, "char_bad", "warning", 0, 0);
      // }
    } else if (studentStatus === "FOCUS") {
      // (ì„ íƒ) ì§‘ì¤‘ ìƒíƒœë¡œ ëŒì•„ì˜¤ë©´ ì˜¤ë²„ë ˆì´ ë„ê¸°? -> í•„ìš” ì‹œ êµ¬í˜„
    }
  }, [studentStatus]);

  const sendAlertToServer = (type: AIStatus) => {
    if (stompClient.current && stompClient.current.connected && studentData) {
      const payload = {
        classid: parseInt(classId),
        studentld: studentData.studentId,
        studentName: studentData.studentName,
        type: type === "SLEEPING" ? "UNFOCUS" : type, // ì„œë²„ ìŠ¤í™ í†µì¼
        detectedAt: new Date().toISOString()
      };
      
      stompClient.current.publish({ 
        destination: "/app/alert", 
        body: JSON.stringify(payload) 
      });
      console.log(`ğŸ“¡ [Digital Alert] ${type}`);
    }
  };

  // ============================================================
  // ğŸ”Œ 3. ì†Œì¼“ ì—°ê²° ë° ì•± ìƒíƒœ ê´€ë¦¬
  // ============================================================
  useEffect(() => {
    if (!studentData) return;

    const client = new Client({
      webSocketFactory: () => new SockJS(SOCKET_CONFIG.BROKER_URL),
      reconnectDelay: 5000,
      onConnect: () => {
        console.log("âœ… [Digital] VisionCam ì†Œì¼“ ì—°ê²° ì„±ê³µ");
        setIsConnected(true);

        const enterPayload = {
          classid: parseInt(classId),
          studentld: studentData.studentId,
          studentName: studentData.studentName
        };
        client.publish({ destination: "/app/enter", body: JSON.stringify(enterPayload) });

        client.subscribe(`/topic/class/${classId}/mode`, (msg) => {
          const body = JSON.parse(msg.body);
          if (body.mode === 'NORMAL') {
            if (OverlayModule) OverlayModule.hideOverlay();
            router.replace('/Classtime_Normal');
          }
        });

        client.subscribe(`/topic/class/${classId}`, (msg) => {
          const body = JSON.parse(msg.body);
          if (body.type === 'CLASS_FINISHED' || body.type === 'END') {
            handleClassEndByTeacher();
          }
        });
      },
      onStompError: (frame) => console.error("âŒ ì†Œì¼“ ì—ëŸ¬:", frame.headers['message']),
    });

    client.activate();
    stompClient.current = client;

    return () => {
      if (stompClient.current) stompClient.current.deactivate();
    };
  }, [studentData]);

  const handleClassEndByTeacher = () => {
    if (OverlayModule) OverlayModule.hideOverlay();
    if (Platform.OS === 'android') OverlayModule.relaunchApp();
    setIsResultVisible(true);
  };

  // PiP ë° ì˜¤ë²„ë ˆì´ ê´€ë¦¬
  useEffect(() => {
    const subscription = AppState.addEventListener("change", (nextAppState) => {
      if (appState.current === "active" && nextAppState.match(/inactive|background/)) {
        if (Platform.OS === 'android' && !isResultVisible) {
          OverlayModule?.showOverlay("ìˆ˜ì—…ì— ì§‘ì¤‘í•˜ê³  ìˆì–´ìš”!", false, "char_1", "city", 0, 0);
          // PipHandler.enterPipMode(500, 500);
        }
      } else if (nextAppState === "active") {
        OverlayModule?.hideOverlay();
      }
      appState.current = nextAppState;
    });
    return () => subscription.remove();
  }, [isResultVisible]);

  // UI ë Œë”ë§
  if (!hasPermission) return <View style={styles.container} />;
  if (device == null) return <ActivityIndicator size="large" color="white" />;

  return (
    <View style={styles.container}>
      {/* ğŸš€ [ì¤‘ìš”] ì¹´ë©”ë¼ëŠ” 1x1 í”½ì…€ë¡œ ì¡´ì¬í•´ì•¼ í”„ë ˆì„ í”„ë¡œì„¸ì„œê°€ ë•ë‹ˆë‹¤ */}
      {/* active={!isResultVisible} : ê²°ê³¼ì°½ ëœ¨ë©´ ì¹´ë©”ë¼ ì¤‘ì§€ */}
      <View style={styles.hiddenCamera}>
        <Camera 
          style={{ flex: 1 }} 
          device={device}
          isActive={!isResultVisible}
          frameProcessor={frameProcessor} // âœ¨ AI ì—°ê²°
          pixelFormat="yuv"
        />
      </View>
      
      {/* <View style={styles.content}>
        <TrafficLight 
          size={inPipMode ? "small" : "large"} 
          status={studentStatus === "SLEEPING" ? "UNFOCUS" : studentStatus} 
        />
      </View> */}

      <ClassResultModal 
        visible={isResultVisible} 
        onClose={() => router.replace('/screens/Student_Home')}
        gainedXP={100} 
      />
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#F5F5F5" },
  // Vision Cameraê°€ ì‘ë™í•˜ë ¤ë©´ ë·°ê°€ ë Œë”ë§ë˜ì–´ ìˆì–´ì•¼ í•˜ë¯€ë¡œ 1x1ë¡œ ìœ ì§€
  hiddenCamera: { position: "absolute", width: 1, height: 1, opacity: 0, zIndex: -1 },
  content: { flex: 1, justifyContent: 'center', alignItems: 'center' },
});